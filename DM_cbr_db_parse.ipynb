{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97aebc76",
   "metadata": {},
   "source": [
    "This code does the following:\n",
    "1. Imports the necessary libraries: xlwt for creating Excel files, BeautifulSoup for parsing HTML, and webdriver for controlling the web browser through Python code.\n",
    "2. Creates an Excel file using the xlwt library and adds two sheets to it.\n",
    "3. Sets the URL of the web page to be scraped.\n",
    "4. Opens a Firefox web browser using webdriver, navigates to the URL, and waits for the page to load.\n",
    "5. Parses the HTML source code of the page using BeautifulSoup and finds all the elements with the class document-regular_name.\n",
    "6. Iterates over the elements found in step 5 and extracts the text from the span tag with the class document-regular_name_visible. The extracted text is then written to the first sheet of the Excel file using xlwt.\n",
    "7. Iterates over all the links on the page and writes their URLs to the second sheet of the Excel file.\n",
    "8. Saves the Excel file with the name test_DB.xls.\n",
    "9. Closes the Firefox web browser.\n",
    "\n",
    "This code can be useful for anyone who needs to extract information from a web page and save it to an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "book = xlwt.Workbook(encoding=\"utf-8\")\n",
    "\n",
    "sheet1 = book.add_sheet(\"Sheet 1\")\n",
    "sheet2 = book.add_sheet(\"Sheet 2\")\n",
    "\n",
    "url = 'https://www.cbr.ru/hd_base/'\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.implicitly_wait(3)\n",
    "driver.get (url)\n",
    "\n",
    "soup = BeautifulSoup (driver.page_source, 'lxml')\n",
    "titles = soup.find_all('div', class_='document-regular_name')\n",
    "\n",
    "p = 4\n",
    "\n",
    "for n, i in enumerate(titles, start=1):\n",
    "    titleName = i.find('span', class_='document-regular_name_visible').text.strip()\n",
    "    p = p+1\n",
    "    sheet1.write(p, 0, titleName)\n",
    "    #print (titleName)\n",
    "\n",
    "for link in soup.findAll('a'):\n",
    "    p = p+1\n",
    "    y = link.get('href')\n",
    "    sheet2.write(p, 0, y)\n",
    "    #print(link.get('href'))\n",
    "    \n",
    "book.save(\"test_DB.xls\")\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit ('3.10.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "be39b3f8db6f6aadae59bee8ccdccf8c340e7c693887d133fde64e2e9d5b4ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
